{
    "V1": "Security architecture has almost become a lost art in many organizations. The days of the enterprise architect\nhave passed in the age of DevSecOps. The application security field must catch up and adopt agile security\nprinciples while re-introducing leading security architecture principles to software practitioners. Architecture is\nnot an implementation, but a way of thinking about a problem that has potentially many different answers,\nand no one single \"correct\" answer. All too often, security is seen as inflexible and demanding that developers\nfix code in a particular way, when the developers may know a much better way to solve the problem. There is\nno single, simple solution for architecture, and to pretend otherwise is a disservice to the software engineering\nfield.\n\nA specific implementation of a web application is likely to be revised continuously throughout its lifetime, but\nthe overall architecture will likely rarely change but evolve slowly. Security architecture is identical - we need\nauthentication today, we will require authentication tomorrow, and we will need it five years from now. If we\nmake sound decisions today, we can save a lot of effort, time, and money if we select and re-use\narchitecturally compliant solutions. For example, a decade ago, multi-factor authentication was rarely\nimplemented.\n\nIf developers had invested in a single, secure identity provider model, such as SAML federated identity, the\nidentity provider could be updated to incorporate new requirements such as NIST 800-63 compliance, while\nnot changing the interfaces of the original application. If many applications shared the same security\narchitecture and thus that same component, they all benefit from this upgrade at once. However, SAML will\nnot always remain as the best or most suitable authentication solution - it might need to be swapped out for\nother solutions as requirements change. Changes like this are either complicated, so costly as to necessitate a\ncomplete re-write, or outright impossible without security architecture.\n\nIn this chapter, the ASVS covers off the primary aspects of any sound security architecture: availability,\nconfidentiality, processing integrity, non-repudiation, and privacy. Each of these security principles must be\nbuilt in and be innate to all applications. It is critical to \"shift left\", starting with developer enablement with\nsecure coding checklists, mentoring and training, coding and testing, building, deployment, configuration, and\noperations, and finishing with follow up independent testing to assure that all of the security controls are\npresent and functional. The last step used to be everything we did as an industry, but that is no longer\nsufficient when developers push code into production tens or hundreds of times a day. Application security\nprofessionals must keep up with agile techniques, which means adopting developer tools, learning to code,\nand working with developers rather than criticizing the project months after everyone else has moved on",
    "V2": "Authentication is the act of establishing, or confirming, someone (or something) as authentic and that claims\nmade by a person or about a device are correct, resistant to impersonation, and prevent recovery or\ninterception of passwords.\n\nWhen the ASVS was first released, username + password was the most common form of authentication\noutside of high security systems. Multi-factor Authentication (MFA) was commonly accepted in security circles\nbut rarely required elsewhere. As the number of password breaches increased, the idea that usernames are\nsomehow confidential and passwords unknown, rendered many security controls untenable. For example,\nNIST 800-63 considers usernames and Knowledge Based Authentication (KBA) as public information, SMS and\nemail notifications as \"restricted\" authenticator types , and passwords as pre-breached. This reality renders\nknowledge based authenticators, SMS and email recovery, password history, complexity, and rotation controls\nuseless. These controls always have been less than helpful, often forcing users to come up with weak\npasswords every few months, but with the release of over 5 billion username and password breaches, it's time\nto move on.\n\nOf all the chapters in the ASVS, the authentication and session management chapters have changed the most.\nAdoption of effective, evidence-based leading practice will be challenging for many, and that's perfectly okay.\nWe have to start the transition to a post-password future now.",
    "V3": "One of the core components of any web-based application or stateful API is the mechanism by which it\ncontrols and maintains the state for a user or device interacting with it. Session management changes a\nstateless protocol to stateful, which is critical for differentiating different users or devices.\n\nEnsure that a verified application satisfies the following high-level session management requirements:\n\n\u2022 Sessions are unique to each individual and cannot be guessed or shared.\n\n\u2022 Sessions are invalidated when no longer required and timed out during periods of inactivity.\n\nAs previously noted, these requirements have been adapted to be a compliant subset of selected NIST 800-\n63b controls, focused around common threats and commonly exploited authentication weaknesses. Previous\nverification requirements have been retired, de-duped, or in most cases adapted to be strongly aligned with\nthe intent of mandatory NIST 800-63b requirements.",
    "V4": "Authorization is the concept of allowing access to resources only to those permitted to use them. Ensure that\na verified application satisfies the following high level requirements:\n\n\u2022 Persons accessing resources hold valid credentials to do so.\n\n\u2022 Users are associated with a well-defined set of roles and privileges.\n\n\u2022 Role and permission metadata is protected from replay or tampering.",
    "V5": "The most common web application security weakness is the failure to properly validate input coming from the\nclient or the environment before directly using it without any output encoding. This weakness leads to almost\nall of the significant vulnerabilities in web applications, such as Cross-Site Scripting (XSS), SQL injection,\ninterpreter injection, locale/Unicode attacks, file system attacks, and buffer overflows.\n\nEnsure that a verified application satisfies the following high-level requirements:\n\n\u2022 Input validation and output encoding architecture have an agreed pipeline to prevent injection attacks.\n\n\u2022 Input data is strongly typed, validated, range or length checked, or at worst, sanitized or filtered.\n\n\u2022 Output data is encoded or escaped as per the context of the data as close to the interpreter as possible.\n\nWith modern web application architecture, output encoding is more important than ever. It is difficult to\nprovide robust input validation in certain scenarios, so the use of safer API such as parameterized queries,\nauto-escaping templating frameworks, or carefully chosen output encoding is critical to the security of the\napplication.",
    "V6": "Ensure that a verified application satisfies the following high level requirements:\n\n\u2022 All cryptographic modules fail in a secure manner and that errors are handled correctly.\n\n\u2022 A suitable random number generator is used.\n\n\u2022 Access to keys is securely managed.",
    "V7": "Ensure that a verified application satisfies the following high level requirements:\n\n\u2022 All cryptographic modules fail in a secure manner and that errors are handled correctly.\n\n\u2022 A suitable random number generator is used.\n\n\u2022 Access to keys is securely managed.",
    "V8": "There are three key elements to sound data protection: Confidentiality, Integrity and Availability (CIA). This\nstandard assumes that data protection is enforced on a trusted system, such as a server, which has been\nhardened and has sufficient protections.\n\nApplications have to assume that all user devices are compromised in some way. Where an application\ntransmits or stores sensitive information on insecure devices, such as shared computers, phones and tablets,\nthe application is responsible for ensuring data stored on these devices is encrypted and cannot be easily\nillicitly obtained, altered or disclosed.\n\nEnsure that a verified application satisfies the following high level data protection requirements:\n\n\u2022 Confidentiality: Data should be protected from unauthorized observation or disclosure both in transit\nand when stored.\n\n\u2022 Integrity: Data should be protected from being maliciously created, altered or deleted by unauthorized\nattackers.\n\n\u2022 Availability: Data should be available to authorized users as required",
    "V9": "Ensure that a verified application meets the following high level requirements:\n\n\u2022 Require TLS or strong encryption, independent of sensitivity of the content.\n\n\u2022 Follow the latest guidance, including:\n\n\t- Configuration advice\n\n\t- Preferred algorithms and ciphers\n\n\u2022 Avoid weak or soon to be deprecated algorithms and ciphers, except as a last resort\n\n\u2022 Disable deprecated or known insecure algorithms and ciphers.\n\nWithin these requirements:\n\n\u2022 Stay current with recommended industry advice on secure TLS configuration, as it changes frequently\n(often due to catastrophic breaks in existing algorithms and ciphers).\n\n\u2022 Use the most recent versions of TLS configuration review tools to configure the preferred order and\nalgorithm selection.\n\n\u2022 Check your configuration periodically to ensure that secure communication is always present and\neffective.",
    "V10": "Ensure that code satisfies the following high level requirements:\n\n\u2022 Malicious activity is handled securely and properly to not affect the rest of the application.\n\n\u2022 Does not have time bombs or other time-based attacks.\n\n\u2022 Does not \"phone home\" to malicious or unauthorized destinations.\n\n\u2022 Does not have back doors, Easter eggs, salami attacks, rootkits, or unauthorized code that can be\ncontrolled by an attacker.\n\nFinding malicious code is proof of the negative, which is impossible to completely validate. Best efforts should\nbe undertaken to ensure that the code has no inherent malicious code or unwanted functionality.",
    "V11": "Ensure that a verified application satisfies the following high level requirements:\n\n\u2022 The business logic flow is sequential, processed in order, and cannot be bypassed.\n\n\u2022 Business logic includes limits to detect and prevent automated attacks, such as continuous small funds\ntransfers, or adding a million friends one at a time, and so on.\n\n\u2022 High value business logic flows have considered abuse cases and malicious actors, and have protections\nagainst spoofing, tampering, information disclosure, and elevation of privilege attacks.",
    "V12": "Ensure that a verified application satisfies the following high level requirements:\n\n\u2022 Untrusted file data should be handled accordingly and in a secure manner.\n\n\u2022 Untrusted file data obtained from untrusted sources are stored outside the web root and with limited\npermissions.",
    "V13": "Ensure that a verified application that uses trusted service layer APIs (commonly using JSON or XML or\nGraphQL) has:\n\n\u2022 Adequate authentication, session management and authorization of all web services.\n\n\u2022 Input validation of all parameters that transit from a lower to higher trust level.\n\n\u2022 Effective security controls for all API types, including cloud and Serverless API",
    "V14": "Ensure that a verified application has:\n\n\u2022 A secure, repeatable, automatable build environment.\n\n\u2022 Hardened third party library, dependency and configuration management such that out of date or\ninsecure components are not included by the application.\n\nConfiguration of the application out of the box should be safe to be on the Internet, which means a safe out of\nthe box configuration.",
    "V1.1": null,
    "V1.2": "When designing authentication, it doesn't matter if you have strong hardware enabled multi-factor\nauthentication if an attacker can reset an account by calling a call center and answering commonly known\nquestions. When proving identity, all authentication pathways must have the same strength.",
    "V1.3": null,
    "V1.4": null,
    "V1.5": "In 4.0, we have moved away from the term \"server-side\" as a loaded trust boundary term. The trust boundary\nis still concerning - making decisions on untrusted browsers or client devices is bypassable. However, in\nmainstream architectural deployments today, the trust enforcement point has dramatically changed.\nTherefore, where the term \"trusted service layer\" is used in the ASVS, we mean any trusted enforcement\npoint, regardless of location, such as a microservice, serverless API, server-side, a trusted API on a client device\nthat has secure boot, partner or external APIs, and so on.\n\nThe \"untrusted client\" term here refers to client-side technologies that render the presentation layer,\ncommonly refered to as 'front-end' technologies. The term \"serialization\" here not only refers to sending data\nover the wire like an array of values or taking and reading a JSON structure, but also passing complex objects\nwhich can contain logic.",
    "V1.6": "Applications need to be designed with strong cryptographic architecture to protect data assets as per their\nclassification. Encrypting everything is wasteful, not encrypting anything is legally negligent. A balance must be\nstruck, usually during architectural or high level design, design sprints or architectural spikes. Designing\ncryptography as you go or retrofitting it will inevitably cost much more to implement securely than simply\nbuilding it in from the start.\n\nArchitectural requirements are intrinsic to the entire code base, and thus difficult to unit or integrate test.\nArchitectural requirements require consideration in coding standards, throughout the coding phase, and\nshould be reviewed during security architecture, peer or code reviews, or retrospectives.",
    "V1.7": null,
    "V1.8": null,
    "V1.9": null,
    "V1.10": null,
    "V1.11": null,
    "V1.12": null,
    "V1.13": null,
    "V1.14": null,
    "V2.1": "Passwords, called \"Memorized Secrets\" by NIST 800-63, include passwords, PINs, unlock patterns, pick the\ncorrect kitten or another image element, and passphrases. They are generally considered \"something you\nknow\", and often used as single-factor authenticators. There are significant challenges to the continued use of\nsingle-factor authentication, including billions of valid usernames and passwords disclosed on the Internet,\ndefault or weak passwords, rainbow tables and ordered dictionaries of the most common passwords.\n\nApplications should strongly encourage users to enroll in multi-factor authentication, and should allow users\nto re-use tokens they already possess, such as FIDO or U2F tokens, or link to a credential service provider that\nprovides multi-factor authentication.\n\nCredential Service Providers (CSPs) provide federated identity for users. Users will often have more than one\nidentity with multiple CSPs, such as an enterprise identity using Azure AD, Okta, Ping Identity or Google, or\nconsumer identity using Facebook, Twitter, Google, or WeChat, to name a just few common alternatives. This\nlist is not an endorsement of these companies or services, but simply an encouragement for developers to\nconsider the reality that many users have many established identities. Organizations should consider\nintegrating with existing user identities, as per the risk profile of the CSP's strength of identity proofing. For\nexample, it is unlikely a government organization would accept a social media identity as a login for sensitive\nsystems, as it is easy to create fake or throw away identities, whereas a mobile game company may well need\nto integrate with major social media platforms to grow their active player base.",
    "V2.2": "Authenticator agility is essential to future-proof applications. Refactor application verifiers to allow additional\nauthenticators as per user preferences, as well as allowing retiring deprecated or unsafe authenticators in an\norderly fashion.\n\nNIST considers email and SMS as \"restricted\" authenticator types, and they are likely to be removed from NIST\n800-63 and thus the ASVS at some point the future. Applications should plan a roadmap that does not require\nthe use of email or SMS.",
    "V2.3": "Authenticators are passwords, soft tokens, hardware tokens, and biometric devices. The lifecycle of\nauthenticators is critical to the security of an application - if anyone can self-register an account with no\nevidence of identity, there can be little trust in the identity assertion. For social media sites like Reddit, that's\nperfectly okay. For banking systems, a greater focus on the registration and issuance of credentials and devices\nis critical to the security of the application.\n\nNote: Passwords are not to have a maximum lifetime or be subject to password rotation. Passwords should be\nchecked for being breached, not regularly replaced",
    "V2.4": "Architects and developers should adhere to this section when building or refactoring code. This section can\nonly be fully verified using source code review or through secure unit or integration tests. Penetration testing\ncannot identify any of these issues.\n\nThe list of approved one-way key derivation functions is detailed in NIST 800-63 B section 5.1.1.2, and in BSI\nKryptographische Verfahren: Empfehlungen und Schlussell\u00e4ngen (2018). The latest national or regional\nalgorithm and key length standards can be chosen in place of these choices.\n\nThis section cannot be penetration tested, so controls are not marked as L1. However, this section is of vital\nimportance to the security of credentials if they are stolen, so if forking the ASVS for an architecture or coding\nguideline or source code review checklist, please place these controls back to L1 in your private version.",
    "V2.5": null,
    "V2.6": "Look up secrets are pre-generated lists of secret codes, similar to Transaction Authorization Numbers (TAN),\nsocial media recovery codes, or a grid containing a set of random values. These are distributed securely to\nusers. These lookup codes are used once, and once all used, the lookup secret list is discarded. This type of\nauthenticator is considered \"something you have\".",
    "V2.7": "In the past, a common out of band verifier would have been an email or SMS containing a password reset link.\nAttackers use this weak mechanism to reset accounts they don't yet control, such as taking over a person's\nemail account and re-using any discovered reset links. There are better ways to handle out of band\nverification.\n\nSecure out of band authenticators are physical devices that can communicate with the verifier over a secure\nsecondary channel. Examples include push notifications to mobile devices. This type of authenticator is\nconsidered \"something you have\". When a user wishes to authenticate, the verifying application sends a\nmessage to the out of band authenticator via a connection to the authenticator directly or indirectly through a\nthird party service. The message contains an authentication code (typically a random six digit number or a\nmodal approval dialog). The verifying application waits to receive the authentication code through the primary\nchannel and compares the hash of the received value to the hash of the original authentication code. If they\nmatch, the out of band verifier can assume that the user has authenticated.\n\nThe ASVS assumes that only a few developers will be developing new out of band authenticators, such as push\nnotifications, and thus the following ASVS controls apply to verifiers, such as authentication API, applications,\nand single sign-on implementations. If developing a new out of band authenticator, please refer to NIST 800-\n63B \u00a7 5.1.3.1.\n\nUnsafe out of band authenticators such as e-mail and VOIP are not permitted. PSTN and SMS authentication\nare currently \"restricted\" by NIST and should be deprecated in favor of push notifications or similar. If you\nneed to use telephone or SMS out of band authentication, please see \u00a7 5.1.3.3.",
    "V2.8": "Single-factor One-time Passwords (OTPs) are physical or soft tokens that display a continually changing\npseudo-random one-time challenge. These devices make phishing (impersonation) difficult, but not\nimpossible. This type of authenticator is considered \"something you have\". Multi-factor tokens are similar to\nsingle-factor OTPs, but require a valid PIN code, biometric unlocking, USB insertion or NFC pairing or some\nadditional value (such as transaction signing calculators) to be entered to create the final OTP.",
    "V2.9": "Cryptographic security keys are smart cards or FIDO keys, where the user has to plug in or pair the\ncryptographic device to the computer to complete authentication. Verifiers send a challenge nonce to the\ncryptographic devices or software, and the device or software calculates a response based upon a securely\nstored cryptographic key.\n\nThe requirements for single-factor cryptographic devices and software, and multi-factor cryptographic devices\nand software are the same, as verification of the cryptographic authenticator proves possession of the\nauthentication factor.",
    "V2.10": "This section is not penetration testable, so does not have any L1 requirements. However, if used in an\narchitecture, coding or secure code review, please assume that software (just as Java Key Store) is the\nminimum requirement at L1. Clear text storage of secrets is not acceptable under any circumstances.",
    "V3.1": null,
    "V3.2": null,
    "V3.3": "Session timeouts have been aligned with NIST 800-63, which permits much longer session timeouts than\ntraditionally permitted by security standards. Organizations should review the table below, and if a longer time\nout is desirable based around the application's risk, the NIST value should be the upper bounds of session idle\ntimeouts.\n\nL1 in this context is IAL1/AAL1, L2 is IAL2/AAL3, L3 is IAL3/AAL3. For IAL2/AAL2 and IAL3/AAL3, the shorter idle\ntimeout is, the lower bound of idle times for being logged out or re-authenticated to resume the session.",
    "V3.4": null,
    "V3.5": "Token-based session management includes JWT, OAuth, SAML, and API keys. Of these, API keys are known to\nbe weak and should not be used in new code.",
    "V3.6": "This section relates to those writing Relying Party (RP) or Credential Service Provider (CSP) code. If relying on\ncode implementing these features, ensure that these issues are handled correctly.",
    "V3.7": "There are a small number of session management attacks, some related to the user experience (UX) of\nsessions. Previously, based on ISO 27002 requirements, the ASVS has required blocking multiple simultaneous\nsessions. Blocking simultaneous sessions is no longer appropriate, not only as modern users have many\ndevices or the app is an API without a browser session, but in most of these implementations, the last\nauthenticator wins, which is often the attacker. This section provides leading guidance on deterring, delaying\nand detecting session management attacks using code.\n\nDescription of the half-open Attack\n\nIn early 2018, several financial institutions were compromised using what the attackers called \"half-open\nattacks\". This term has stuck in the industry. The attackers struck multiple institutions with different\nproprietary code bases, and indeed it seems different code bases within the same institutions. The half-open\nattack is exploiting a design pattern flaw commonly found in many existing authentication, session\nmanagement and access control systems.\n\nAttackers start a half-open attack by attempting to lock, reset, or recover a credential. A popular session\nmanagement design pattern re-uses user profile session objects/models between unauthenticated, halfauthenticated (password resets, forgot username), and fully authenticated code. This design pattern populates\na valid session object or token containing the victim's profile, including password hashes and roles. If access\ncontrol checks in controllers or routers does not correctly verify that the user is fully logged in, the attacker\nwill be able to act as the user. Attacks could include changing the user's password to a known value, update\nthe email address to perform a valid password reset, disable multi-factor authentication or enroll a new MFA\ndevice, reveal or change API keys, and so on.",
    "V4.1": null,
    "V4.2": null,
    "V4.3": null,
    "V5.1": "Properly implemented input validation controls, using positive allow lists and strong data typing, can eliminate\nmore than 90\\% of all injection attacks. Length and range checks can reduce this further. Building in secure\ninput validation is required during application architecture, design sprints, coding, and unit and integration\ntesting. Although many of these items cannot be found in penetration tests, the results of not implementing\nthem are usually found in V5.3 - Output encoding and Injection Prevention Requirements. Developers and\nsecure code reviewers are recommended to treat this section as if L1 is required for all items to prevent\ninjections.",
    "V5.2": null,
    "V5.3": "Output encoding close or adjacent to the interpreter in use is critical to the security of any application.\nTypically, output encoding is not persisted, but used to render the output safe in the appropriate output\ncontext for immediate use. Failing to output encode will result in an insecure, injectable, and unsafe\napplication.",
    "V5.4": "The following requirements will only apply when the application uses a systems language or unmanaged code.",
    "V5.5": null,
    "V6.1": "The most important asset is the data processed, stored or transmitted by an application. Always perform a\nprivacy impact assessment to classify the data protection needs of any stored data correctly.",
    "V6.2": "Recent advances in cryptography mean that previously safe algorithms and key lengths are no longer safe or\nsufficient to protect data. Therefore, it should be possible to change algorithms.\n\nAlthough this section is not easily penetration tested, developers should consider this entire section as\nmandatory even though L1 is missing from most of the items.",
    "V6.3": "True Pseudo-random Number Generation (PRNG) is incredibly difficult to get right. Generally, good sources of\nentropy within a system will be quickly depleted if over-used, but sources with less randomness can lead to\npredictable keys and secrets.",
    "V6.4": "Although this section is not easily penetration tested, developers should consider this entire section as\nmandatory even though L1 is missing from most of the items.",
    "V7.1": "Logging sensitive information is dangerous - the logs become classified themselves, which means they need to\nbe encrypted, become subject to retention policies, and must be disclosed in security audits. Ensure only\nnecessary information is kept in logs, and certainly no payment, credentials (including session tokens),\nsensitive or personally identifiable information.",
    "V7.2": "Timely logging is critical for audit events, triage, and escalation. Ensure that the application's logs are clear and\ncan be easily monitored and analyzed either locally or log shipped to a remote monitoring system.",
    "V7.3": "Logs that can be trivially modified or deleted are useless for investigations and prosecutions. Disclosure of logs\ncan expose inner details about the application or the data it contains. Care must be taken when protecting logs\nfrom unauthorized disclosure, modification or deletion.",
    "V7.4": "The purpose of error handling is to allow the application to provide security relevant events for monitoring,\ntriage and escalation. The purpose is not to create logs. When logging security related events, ensure that\nthere is a purpose to the log, and that it can be distinguished by SIEM or analysis software.",
    "V8.1": null,
    "V8.2": null,
    "V8.3": "This section helps protect sensitive data from being created, read, updated, or deleted without authorization,\nparticularly in bulk quantities.\n\nCompliance with this section implies compliance with V4 Access Control, and in particular V4.2. For example,\nto protect against unauthorized updates or disclosure of sensitive personal information requires adherence to\nV4.2.1. Please comply with this section and V4 for full coverage.\n\nNote: Privacy regulations and laws, such as the Australian Privacy Principles APP-11 or GDPR, directly affect\nhow applications must approach the implementation of storage, use, and transmission of sensitive personal\ninformation. This ranges from severe penalties to simple advice. Please consult your local laws and regulations,\nand consult a qualified privacy specialist or lawyer as required.",
    "V9.1": "Ensure all client messages are sent over encrypted networks, using TLS 1.2 or later. Use up to date tools to\nreview the client configuration on a regular basis.",
    "V9.2": "Server communications are more than just HTTP. Secure connections to and from other systems, such as\nmonitoring systems, management tools, remote access and ssh, middleware, database, mainframes, partner\nor external source systems \u2014 must be in place. All of these must be encrypted to prevent \"hard on the\noutside, trivially easy to intercept on the inside\".",
    "V10.1": "The best defense against malicious code is \"trust, but verify\". Introducing unauthorized or malicious code into\ncode is often a criminal offence in many jurisdictions. Policies and procedures should make sanctions regarding\nmalicious code clear.\n\nLead developers should regularly review code check-ins, particularly those that might access time, I/O, or\nnetwork functions.",
    "V10.2": "Malicious code is extremely rare and is difficult to detect. Manual line by line code review can assist looking for\nlogic bombs, but even the most experienced code reviewer will struggle to find malicious code even if they\nknow it exists.\n\nComplying with this section is not possible without complete access to source code, including third-party\nlibraries.",
    "V10.3": "Once an application is deployed, malicious code can still be inserted. Applications need to protect themselves\nagainst common attacks, such as executing unsigned code from untrusted sources and subdomain takeovers.\nComplying with this section is likely to be operational and continuous.",
    "V11.1": "Business logic security is so individual to every application that no one checklist will ever apply. Business logic\nsecurity must be designed in to protect against likely external threats - it cannot be added using web\napplication firewalls or secure communications. We recommend the use of threat modeling during design\nsprints, for example using the OWASP Cornucopia or similar tools.",
    "V12.1": "Although zip bombs are eminently testable using penetration testing techniques, they are considered L2 and\nabove to encourage design and development consideration with careful manual testing, and to avoid\nautomated or unskilled manual penetration testing of a denial of service condition",
    "V12.2": null,
    "V12.3": null,
    "V12.4": null,
    "V12.5": null,
    "V12.6": null,
    "V13.1": null,
    "V13.2": "JSON schema validation is in a draft stage of standardization (see references). When considering using JSON\nschema validation, which is best practice for RESTful web services, consider using these additional data\nvalidation strategies in combination with JSON schema validation:\n\n\u2022 Parsing validation of the JSON object, such as if there are missing or extra elements.\n\n\u2022 Validation of the JSON object values using standard input validation methods, such as data type, data\nformat, length, etc.\n\n\u2022 and formal JSON schema validation.\n\nOnce the JSON schema validation standard is formalized, ASVS will update its advice in this area. Carefully\nmonitor any JSON schema validation libraries in use, as they will need to be updated regularly until the\nstandard is formalized and bugs are ironed out of reference implementations.",
    "V13.3": null,
    "V13.4": null,
    "V14.1": "Build pipelines are the basis for repeatable security - every time something insecure is discovered, it can be\nresolved in the source code, build or deployment scripts, and tested automatically. We are strongly\nencouraging the use of build pipelines with automatic security and dependency checks that warn or break the\nbuild to prevent known security issues being deployed into production. Manual steps performed irregularly\ndirectly leads to avoidable security mistakes.\n\nAs the industry moves to a DevSecOps model, it is important to ensure the continued availability and integrity\nof deployment and configuration to achieve a \"known good\" state. In the past, if a system was hacked, it\nwould take days to months to prove that no further intrusions had taken place. Today, with the advent of\nsoftware defined infrastructure, rapid A/B deployments with zero downtime, and automated containerized\nbuilds, it is possible to automatically and continuously build, harden, and deploy a \"known good\" replacement\nfor any compromised system.\n\nIf traditional models are still in place, then manual steps must be taken to harden and back up that\nconfiguration to allow the compromised systems to be quickly replaced with high integrity, uncompromised\nsystems in a timely fashion.\n\nCompliance with this section requires an automated build system, and access to build and deployment scripts.",
    "V14.2": "Dependency management is critical to the safe operation of any application of any type. Failure to keep up to\ndate with outdated or insecure dependencies is the root cause of the largest and most expensive attacks to\ndate.\n\nNote: At Level 1, 14.2.1 compliance relates to observations or detections of client-side and other libraries and\ncomponents, rather than the more accurate build-time static code analysis or dependency analysis. These\nmore accurate techniques could be discoverable by interview as required.",
    "V14.3": "Configurations for production should be hardened to protect against common attacks, such as debug consoles,\nraise the bar for Cross-site Scripting (XSS) and Remote File Inclusion (RFI) attacks, and to eliminate trivial\ninformation discovery \"vulnerabilities\" that are the unwelcome hallmark of many penetration testing reports.\nMany of these issues are rarely rated as a significant risk, but they are chained together with other\nvulnerabilities. If these issues are not present by default, it raises the bar before most attacks can succeed.",
    "V14.4": null,
    "V14.5": null
}